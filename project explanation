Hi everyone, I'm Sumanth.

Today, I’ll be demonstrating two key modules that are essential in day-to-day DevOps operations:

Deploying applications to Kubernetes using Jenkins – showcasing how CI/CD pipelines automate the deployment process.

Monitoring and Logging – highlighting how tools like Prometheus, Grafana, Loki, and various agents help monitor infrastructure and applications for better reliability and performance.

Let’s dive in!

Let’s start with how I provisioned the infrastructure for this deployment:

I used Bicep templates—Azure’s Infrastructure as Code language—to provision the core network components like the Virtual Network (VNet) and a Jenkins VM.

Then, using the Azure Portal, I deployed the following essential services:

AKS Cluster – to orchestrate and manage our containerized applications.

Azure Container Registry (ACR) – to store and manage Docker images.

Azure SQL Database – serving as the backend database for the application.

Azure Key Vault – for securely storing and accessing secrets and credentials.

This forms the foundation for our application deployment and monitoring setup.

Now, let’s walk through the Jenkinsfile that automates our deployment process:

The Jenkinsfile defines the CI/CD pipeline, and here are the key stages:


EXPLAIN EVERYTHING AND GIVE A DEMO BY REGISTRING A NEW USER AND SEEING THE DATA IN AZURE SQL DATABSE.

One important highlight of my setup is the use of Managed Identities.

Instead of hardcoding credentials, I configured Managed Identities for resources like the AKS cluster and Jenkins VM to securely access Azure Key Vault.

This enhances security by eliminating the need to store secrets in code or pipelines.

Additionally, I implemented SSL/TLS certificates to enable HTTPS for secure communication with our deployed service—ensuring both data integrity and confidentiality.




---------------------------------------------------------------
Now, let’s talk about the Grafana Monitoring & Logging Stack.

I installed both Loki and Prometheus as the core components for logging and metrics collection.

To collect logs and metrics, I deployed supporting agents:

Promtail for forwarding logs to Loki,

Node Exporter, Process Exporter, Kube-State-Metrics, and cAdvisor to gather metrics at the node, process, and container levels.

I configured Prometheus to scrape metrics from these agents, ensuring continuous data collection.

Finally, I added Loki and Prometheus as data sources in Grafana, enabling powerful dashboards for real-time monitoring and log analysis.

This completes a secure and scalable observability setup for both infrastructure and applications.









